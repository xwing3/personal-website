var store = [{
        "title": "Welcome",
        "excerpt":"Hi and like the title suggest, welcome to my personal website, blog, voice on the Internet, etc.  ","categories": ["First step"],
        "tags": ["welcome","bienvenue","bineativenit","willkommen"],
        "url": "https://www.florianmadar.com/first%20step/first-post/",
        "teaser":null},{
        "title": "Various ways to tail Kubernetes pod logs",
        "excerpt":"I’ve been using Kubernetes as the main container orchestration software for almost two years and during that period I’ve tried different ways to tail container logs, some of which were even third party cloud logging services like Google Logging, but still the fastest way is using a CLI tool and thankfully there are a couple to choose from.  Kubectl  Platforms supported: Linux, MacOS, Windows  Kubectl remains the default go to tool for tailing containers logs.   Usage:    kubectl logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER]  Using it with -f will allow you to stream the logs, -p is for printing the logs of the previous pod/container instance and -c is used to specify the container name if you have a pod in which resides multiple containers.  More about this robust kubectl command can be found at Kubernetes homepage.   Stern  Platforms supported: Linux, MacOS  My all time favorite although I started using it really late, stern is a tool made by Wercker which recently were acquired by Oracle and it allows you to tail multiple pods/containers. The results are colored coded to improve readability and debugging and it supports regular expressions use in query so you can easily filter K8s pods/containers without the need to specify the exact id.   Usage:   stern pod-query [flags]  For the whole list of flags and other features you can checkout their Github page.   Kubetail  Platforms supported: Linux, MacOS  If the need arises to tail multiple logs from multiple pods Kubetail is an option that you surely can consider. It’s a robust bash script that does kubectl logs -f but for multiple pods.  A few  noteworthy features that it supports:     Regular expressions: kubetail \"^app1|.*my-demo.*\" --regex   Tail multiple pods: kubetail app1,app2   Tail multiple specific containers: kubetail app2 -c container1 -c container2   Check their Github page  for more.   Kail  Platforms supported: Linux, MacOS, Windows  Kail is another worthy mention, it does the same job as stern and kubetail. Their Github page contains detailed information about the features it supports.   EndPost  Basically these are some of the tools out there that are used to stream pod logs. I mostly go with Kubectl but started recently to use Stern as it offers more flexibility and features.  ","categories": ["Kubernetes"],
        "tags": ["Kubernetes","kubetail","logs","kubectl","stern","kail"],
        "url": "https://www.florianmadar.com/kubernetes/tail-kubernetes-logs/",
        "teaser":null},{
        "title": "Easily create an EKS cluster in AWS using eksctl",
        "excerpt":"For me, not a while ago, Kubernetes cluster administration and creation in AWS was synonymous with kops as their cloud build Kubernetes service (EKS) was lacking features and was a handful when it came to creating and administrating a cluster. Since then things took a turn for the best, new tools were developed and made creation and administration of an EKS clusters more pleasant.  Such a tool is eksctl created and maintained by Weaveworks. Eksctl is a CLI tool built in GO that helps with creation of AWS EKS clusters.  You can easily create a cluster using eksctl with a simple command line instruction where you can specify the name, Kubernetes version, AWS region, the name of the worker nodegroup, EC2 machine node-type, number of nodes from the get go, a minimum number and a maximum number of nodes for autoscalling purposes and if you want the node group to be managed and provisioned by AWS EKS which you certainly want to:       eksctl create cluster \\     --name prod \\     --version 1.14 \\     --region eu-central-1 \\     --nodegroup-name prod_node_group \\     --node-type t3.large \\     --nodes 2 \\     --nodes-min 1 \\     --nodes-max 3 \\     --managed  If you are an adept of IAC (Infrastructure as code) you can in depth customize your cluster by using a yaml config file:   apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig  metadata:   name: prod   region: eu-central-1   version: 1.14  managedNodeGroups:   - name: prod     instanceType: t3.large     desiredCapacity: 1     availabilityZones: [\"eu-central-1a\"]     minSize: 1     maxSize: 3     tags:           nodegroup-role: worker     labels: {role: worker}     iam:       withAddonPolicies:         externalDNS: true         certManager: true  The config above is similar to the CLI instruction but it also adds new options for customization like specifying availabilityZones, addons policies and many more, a full list of features can be found at eksctl homepage.   The yaml config can be easily applied using: eksctl create cluster -f cluster.yaml.  EndPost  Eksctl is a great tool that simplifies cluster creation and even Amazon recommends using it in their official documentation.   ","categories": ["Kubernetes"],
        "tags": ["Kubernetes","eks","eksctl","aws"],
        "url": "https://www.florianmadar.com/kubernetes/eks-cluster-creation-aws/",
        "teaser":null},{
        "title": "Deploying with Kubernetes - Namespace segregation",
        "excerpt":"In Kubernetes, namespaces are a powerful concept that offers a way to partition a single Kubernetes cluster into multiple virtual clusters or, in our case, multiple environments.  Kubernetes namespace segregation is used for a variety of reasons of which includes:     divide cluster resources between multiple users   provide a scope to names - names need to be unique inside the scope of a namespace but not across namespaces   restrict access to different environments using RBAC (Role base access control)/namespace   partition development landscapes   Partition development landscape  This post focuses on partition development landscape. One of the advantages that Kubernetes provides is the ability for software development teams to partition their development pipelines into standalone units to manage various environments easier and better than traditional deployment strategies.  For most applications, you have dev, QA, staging, and production environments. The resulting structure is ideally suited to Kubernetes namespaces. Each environment or stage in the pipeline becomes a unique namespace.   The deployment process using partition development is best represented by the below flowchart:  Developers commit the source code to a code repository, CI/CD pipeline jobs are then run to test/build/push the Docker images to a Docker Images Registry service and then a pipeline job that uses helm or kubectl to update the Kubernetes deployment images is executed making this a straight forward and easy to understand deployment scenario.  ","categories": ["Kubernetes"],
        "tags": ["Kubernetes","namespace","deploy","environment"],
        "url": "https://www.florianmadar.com/kubernetes/kubernetes-namespace-segregation/",
        "teaser":null}]
